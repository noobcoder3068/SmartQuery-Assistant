{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KO2dN9WwA3su",
        "outputId": "667c7c96-c1eb-4493-a976-d1e37cac9303"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IxHjmx9ucWkV",
        "outputId": "7a2fa195-3a86-4ef4-a809-fb24f5363853"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.46.1-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.8.1)\n",
            "Requirement already satisfied: torch<3,>=2.2 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.6.0+cu124)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (25.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate) (6.0.2)\n",
            "Requirement already satisfied: huggingface_hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.33.4)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.5.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (2025.3.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.21.0->accelerate) (1.1.5)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch<3,>=2.2->bitsandbytes)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch<3,>=2.2->bitsandbytes)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch<3,>=2.2->bitsandbytes)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch<3,>=2.2->bitsandbytes)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch<3,>=2.2->bitsandbytes)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch<3,>=2.2->bitsandbytes)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch<3,>=2.2->bitsandbytes)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch<3,>=2.2->bitsandbytes)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch<3,>=2.2->bitsandbytes)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch<3,>=2.2->bitsandbytes)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3,>=2.2->bitsandbytes) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3,>=2.2->bitsandbytes) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2025.7.14)\n",
            "Downloading bitsandbytes-0.46.1-py3-none-manylinux_2_24_x86_64.whl (72.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.9/72.9 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m89.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m66.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m107.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, bitsandbytes\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed bitsandbytes-0.46.1 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ],
      "source": [
        "pip install bitsandbytes accelerate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rrw9RHvqYkSb",
        "outputId": "dcb75a10-939a-4035-d791-2c408db965ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/MyDrive/natural-sql-7b.zip\n",
            "   creating: /content/natural-sql-7b/natural-sql-7b/\n",
            "  inflating: /content/natural-sql-7b/natural-sql-7b/config.json  \n",
            "  inflating: /content/natural-sql-7b/natural-sql-7b/model-00001-of-00003.safetensors  \n",
            "  inflating: /content/natural-sql-7b/natural-sql-7b/model-00002-of-00003.safetensors  \n",
            "  inflating: /content/natural-sql-7b/natural-sql-7b/model-00003-of-00003.safetensors  \n",
            "  inflating: /content/natural-sql-7b/natural-sql-7b/model.safetensors.index.json  \n",
            "  inflating: /content/natural-sql-7b/natural-sql-7b/special_tokens_map.json  \n",
            "  inflating: /content/natural-sql-7b/natural-sql-7b/tokenizer.json  \n",
            "  inflating: /content/natural-sql-7b/natural-sql-7b/tokenizer_config.json  \n"
          ]
        }
      ],
      "source": [
        "!unzip \"/content/drive/MyDrive/natural-sql-7b.zip\" -d \"/content/natural-sql-7b\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZrPpoIGtbw8m",
        "outputId": "aaeb0e3f-a1a6-4e21-9986-831317920391"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers==4.35.2\n",
            "  Downloading transformers-4.35.2-py3-none-any.whl.metadata (123 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/123.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.5/123.5 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.35.2) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from transformers==4.35.2) (0.33.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.35.2) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.35.2) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.35.2) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.35.2) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.35.2) (2.32.3)\n",
            "Collecting tokenizers<0.19,>=0.14 (from transformers==4.35.2)\n",
            "  Downloading tokenizers-0.15.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.35.2) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.35.2) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers==4.35.2) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers==4.35.2) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers==4.35.2) (1.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.35.2) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.35.2) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.35.2) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.35.2) (2025.7.14)\n",
            "Downloading transformers-4.35.2-py3-none-any.whl (7.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m77.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.15.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m85.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tokenizers, transformers\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.21.2\n",
            "    Uninstalling tokenizers-0.21.2:\n",
            "      Successfully uninstalled tokenizers-0.21.2\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.53.2\n",
            "    Uninstalling transformers-4.53.2:\n",
            "      Successfully uninstalled transformers-4.53.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "sentence-transformers 4.1.0 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.35.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed tokenizers-0.15.2 transformers-4.35.2\n"
          ]
        }
      ],
      "source": [
        "pip install transformers==4.35.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190,
          "referenced_widgets": [
            "c7052da3c8a64b23a3e324be64c9d4ae",
            "1dbe3ffd993d474996c58c9ae21f0910",
            "d58727995b0143fe929cb8a700093144",
            "eed41c4597df4625a585f27ca1d433e0",
            "df11883ce94f4438bd4bb03c4432f258",
            "945a714f3506408fa4acbde95435702a",
            "81b9d68bff8042f890c7a43562a47b1d",
            "754cff8ce3f54fc2979bee33b50b52ee",
            "c7171830fe7b42c4a75e2dad25fdbdad",
            "2aefc576bad744aca9060ae165e3a7af",
            "4f08fe1cea084c37a649b350e0c3c6ef"
          ]
        },
        "id": "P9ClrP1zZSU2",
        "outputId": "acb785cb-5e37-4361-de11-11150cb330ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  _torch_pytree._register_pytree_node(\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  _torch_pytree._register_pytree_node(\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
            "  _torch_pytree._register_pytree_node(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c7052da3c8a64b23a3e324be64c9d4ae"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "model_path = \"/content/natural-sql-7b/natural-sql-7b\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_path,\n",
        "    device_map=\"auto\",\n",
        "    torch_dtype=\"auto\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lj-ioTr7nw6x",
        "outputId": "5cb614a5-4d98-4551-9f38-0012958016fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.11.0.post1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (25.0)\n",
            "Downloading faiss_cpu-1.11.0.post1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (31.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.3/31.3 MB\u001b[0m \u001b[31m49.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.11.0.post1\n"
          ]
        }
      ],
      "source": [
        "!pip install faiss-cpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55tC-3fzoMOW",
        "outputId": "6fbef2c6-7bfb-48a4-faa4-dee624f76e5f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting psycopg2-binary\n",
            "  Downloading psycopg2_binary-2.9.10-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Downloading psycopg2_binary-2.9.10-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/3.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/3.0 MB\u001b[0m \u001b[31m60.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/3.0 MB\u001b[0m \u001b[31m60.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: psycopg2-binary\n",
            "Successfully installed psycopg2-binary-2.9.10\n"
          ]
        }
      ],
      "source": [
        "!pip install psycopg2-binary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4w1OoKbbks7",
        "outputId": "1cc1e752-319b-453f-9ec1-820e81e5d7f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Loaded 2 chunks\n"
          ]
        }
      ],
      "source": [
        "import faiss, pickle\n",
        "\n",
        "# Paths to Drive\n",
        "chunk_path = \"/content/drive/MyDrive/chunk_conv/rag_chunks.pkl\"\n",
        "index_path = \"/content/drive/MyDrive/chunk_conv/rag_index.faiss\"\n",
        "\n",
        "# Load\n",
        "with open(chunk_path, \"rb\") as f:\n",
        "    chunks = pickle.load(f)\n",
        "\n",
        "index = faiss.read_index(index_path)\n",
        "\n",
        "print(f\"✅ Loaded {len(chunks)} chunks\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "smEC98VE2k_l",
        "outputId": "a5e9b5c7-389a-4915-fca3-2ccf7e711044"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': tensor([[100000,     13,    185,    185,   1567,  16086,  15467,  13862,  16111,\n",
            "            280,    779,  25201,    856,     11,    754,     11,    285,    946,\n",
            "           1972,  97164,    938,   3863,    837,  27253,  17867,     11,   5424,\n",
            "          79581,     11,    285,   1590,     12,   2926,   2462,  15403,   3246,\n",
            "          10929,  10582,    185,    185,   6894,    185,    185,   1567,   4902,\n",
            "            317,   5405,    276,   1855,   2462,   2689,    285,  27253,  16111,\n",
            "           3246,    274,   7902,     13,    809,    317,  26932,   1983,   1853,\n",
            "           2131,   7208,     25,   4378,     11,  21435,     62,  16088,     11,\n",
            "            285,   2462,     62,  12140,     13,    429,   4378,   2376,  11750,\n",
            "            372,    254,   6327,   2123,     11,  33765,    521,   2462,   6929,\n",
            "             13,   7915,   5451,    279,    437,   2376,   9622,    274,   3451,\n",
            "           2462,   2536,    285,   5312,   4295,   1108,    372,    254,   2536,\n",
            "           4993,    334,    305,    654,    254,   7902,   4993,    334,   2167,\n",
            "            305,    654,    254,   2677,   4993,    334,   2167,  67423,    654,\n",
            "            285,    254,   2462,   1420,   4993,    334,  10533,   3784,    305,\n",
            "            633,    809,    839,   8727,    254,    766,    280,    254,   2536,\n",
            "           1244,   5633,    837,   2536,   2926,  58111,     11,    766,     89,\n",
            "          19127,   5990,   2926,     11,    285,  65183,  25630,     13,  26108,\n",
            "          17074,   1108,    372,   5489,    334,   8468,    410,  10998,    654,\n",
            "           2536,   2150,    334,     68,     13,     70,   1797,  24941,    410,\n",
            "          53870,    654,    909,    257,    292,    773,    334,     68,     13,\n",
            "             70,   1797,   7355,     11,   3059,     11,   3995,    654,    285,\n",
            "           7355,  10533,   9529,    334,     68,     13,     70,   1797,  13952,\n",
            "             62,    580,     62,  10533,     11,  30245,      8,   1345,   5933,\n",
            "            254,   4910,    280,    254,   2462,     13,    185,    185,    549,\n",
            "          21435,     62,  16088,   2376,   9831,   1319,   3594,  67423,    276,\n",
            "            274,   3451,   2677,     13,   1002,   2376,   5312,   3675,   4295,\n",
            "           1108,    372,    254,   2677,      6,     82,   1210,     11,  73604,\n",
            "             11,  14055,   4998,     11,    285,   1719,  23805,   1834,     13,\n",
            "            809,    317,   1222,    276,   6417,    366,    254,   4378,   2376,\n",
            "           3764,    254,   3594,  67423,   3823,    276,  24087,    779,   7903,\n",
            "           1319,   2462,   3439,     13,    185,    185,    549,   2462,     62,\n",
            "          12140,   2376,   4614,  17074,    786,   5315,  10582,   5329,    366,\n",
            "           2462,   2689,   6211,     13,   7915,   2462,   1420,    317,  10730,\n",
            "            457,    274,   2462,   3784,    305,    285,   5312,   5633,   1108,\n",
            "            372,   2462,   3784,   1531,     11,    327,   9517,     11,    327,\n",
            "          88636,    649,     11,   4167,   4438,     11,    285,  65909,     13,\n",
            "           1002,   2376,    317,  10213,    366,    254,   4378,   2376,    331,\n",
            "           2462,   3784,    305,    276,   6983,   1066,    254,   2536,  11129,\n",
            "             13,    185,    185,   2219,   6027,  12314,    754,   2695,    366,\n",
            "            437,   4902,    317,    344,    521,   2432,    285,  17468,  10114,\n",
            "            418,   1460,     12,  36590,    457,   3363,     13,   1002,   5312,\n",
            "          10114,    837,   1210,     11,   2462,   3784,   1531,     11,   2536,\n",
            "           2150,     11,    285,    909,    257,    292,    773,     13,   7536,\n",
            "             11,    276,   5462,  12261,   5162,   6872,  14607,    280,   2432,\n",
            "          70801,     11,    938,  19108,     40,   7576,   3615,    280,    403,\n",
            "            279,   5981,  12750,    754,  25325,   1069,  10114,     13,   1494,\n",
            "           2203,     11,   3615,    280,   4456,  11267,   2462,   3784,   1531,\n",
            "            403,    655,  12272,  22425,   1185,    938,  11267,   2462,   3784,\n",
            "           1531,  19108,     40,   7576,    655,  12272,  22425,      6,    276,\n",
            "           4174,   3039,  14607,    280,    704,   5371,   1460,     13,    185,\n",
            "            185,   1898,   5592,   5463,  12750,     11,   6417,   4378,     13,\n",
            "           2167,  67423,    366,  21435,     62,  16088,     13,   2167,  67423,\n",
            "            276,  20582,   2462,   4378,    366,   3451,   4741,     13,   7305,\n",
            "           4378,     13,  10533,   3784,    305,  10213,    366,   2462,     62,\n",
            "          12140,     13,  10533,   3784,    305,    276,  16893,   4924,     12,\n",
            "           4912,   1191,     13,   2473,  25325,    457,   2462,   4786,     11,\n",
            "            938,    909,    257,    292,    773,    285,   7355,  10533,   9529,\n",
            "             13,   2158,  40265,    766,     12,  15953,   8727,     11,  28828,\n",
            "            766,     89,  19127,   5990,   2926,     11,   4290,     11,    410,\n",
            "            766,     13,    185,    185,   1567,  16086,  15467,  13862,  16111,\n",
            "            280,    779,  25201,    856,     11,    754,     11,    285,    946,\n",
            "           1972,  97164,    938,   3863,    837,  27253,  17867,     11,   5424,\n",
            "          79581,     11,    285,   1590,     12,   2926,   2462,  15403,   3246,\n",
            "          10929,  10582,    185,    185,   6894,    185,    185,     13,    185,\n",
            "            185,   1567,  16086,  15467,  13862,  16111,    280,    779,  25201,\n",
            "            856,     11,    754,     11,    285,    946,   1972,  97164,    938,\n",
            "           3863,    837,  27253,  17867,     11,   5424,  79581,     11,    285,\n",
            "           1590,     12,   2926,   2462,  15403,   3246,  10929,  10582,    185,\n",
            "            185,   6894,    185,    185,  23853,     25,    185,    249,    588,\n",
            "          13533,  78135,  10567,    531,    438,   1828,    279,   1864,   2562,\n",
            "            280,    523,   3122,    207,     17,     15,     17,     20,    185,\n",
            "            185,   6232,     25]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1]], device='cuda:0')}\n"
          ]
        }
      ],
      "source": [
        "with open(\"/content/drive/MyDrive/chunk_conv/context.txt\", \"r\") as f:\n",
        "    prompt = f.read()\n",
        "\n",
        "inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
        "# outputs = model.generate(**inputs, max_new_tokens=256)\n",
        "print(inputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aNAYTxBavRPA",
        "outputId": "93f20aff-35d8-469a-d587-ae71b94b4bb4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:100001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".\n",
            "\n",
            "This schema enables comprehensive tracking of who accessed what, when, and how—supporting use cases like attendance logging, security auditing, and real-time access monitoring across distributed locations\n",
            "\n",
            "---\n",
            "\n",
            "This database is designed to support access control and attendance tracking across an organization. It is structured around three key tables: events, organisation_users, and access_points. The events table acts as the central log, capturing all access activity. Each row in this table represents an individual access event and includes details such as the event ID (id), the organization ID (orgid), the user ID (orguserid), and the access point ID (accesspointid). It also records the time of the event using fields like eventtimeepoch, timezonedeventtime, and tzdatetime. Additional metadata such as direction (entry or exit), eventtype (e.g., authorized or unauthorized), accesstype (e.g., mobile, face, card), and mobileaccessmode (e.g., tap_to_access, proximity) help define the nature of the access.\n",
            "\n",
            "The organisation_users table maps each orguserid to an individual user. This table includes personal details such as the user's name, userId, employeeCode, and homeSiteId. It is used to join with the events table via the orguserid column to retrieve who performed each access action.\n",
            "\n",
            "The access_points table provides metadata about physical locations associated with access control devices. Each access point is identified by an accesspointid and includes fields such as accesspointname, forAccess, forAttendance, doorState, and timezone. This table is joined with the events table on accesspointid to determine where the event occurred.\n",
            "\n",
            "An essential consideration when working with this database is that all text and varchar columns are case-sensitive by default. This includes columns like name, accesspointname, eventtype, and accesstype. Therefore, to ensure reliable query behavior regardless of text casing, use ILIKE instead of = in SQL queries when filtering these columns. For example, instead of writing WHERE accesspointname = 'Main Gate', use WHERE accesspointname ILIKE 'Main Gate' to match values regardless of their letter case.\n",
            "\n",
            "To construct effective queries, join events.orguserid with organisation_users.orguserid to associate access events with individual users. Use events.accesspointid joined with access_points.accesspointid to fetch location-based data. When filtering by access methods, use accesstype and mobileaccessmode. To isolate time-specific records, leverage timezonedeventtime, date, or time.\n",
            "\n",
            "This schema enables comprehensive tracking of who accessed what, when, and how—supporting use cases like attendance logging, security auditing, and real-time access monitoring across distributed locations\n",
            "\n",
            "---\n",
            "\n",
            ".\n",
            "\n",
            "This schema enables comprehensive tracking of who accessed what, when, and how—supporting use cases like attendance logging, security auditing, and real-time access monitoring across distributed locations\n",
            "\n",
            "---\n",
            "\n",
            "Question:\n",
            "on which dates adam ruiz was present in second week of june 2025\n",
            "\n",
            "SQL:\n",
            "SELECT DISTINCT date\n",
            "FROM events\n",
            "JOIN organisation_users ON events.orguserid = organisation_users.orguserid\n",
            "WHERE organisation_users.name ILIKE '%Adam Ruiz%'\n",
            "AND timezonedeventtime >= '2025-06-14 00:00:00'\n",
            "AND timezonedeventtime < '2025-06-21 23:59:59';\n"
          ]
        }
      ],
      "source": [
        "outputs = model.generate(**inputs, max_new_tokens=256)\n",
        "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3PrlxeySvVvD",
        "outputId": "c37e857d-1e3a-4738-8b80-78f5e1d50727"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted Question:\n",
            " on which dates adam ruiz was present in second week of june 2025\n",
            "\n",
            "Extracted SQL:\n",
            " SELECT DISTINCT date\n",
            "FROM events\n",
            "JOIN organisation_users ON events.orguserid = organisation_users.orguserid\n",
            "WHERE organisation_users.name ILIKE '%Adam Ruiz%'\n",
            "AND timezonedeventtime >= '2025-06-14 00:00:00'\n",
            "AND timezonedeventtime < '2025-06-21 23:59:59';\n"
          ]
        }
      ],
      "source": [
        "output_str = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "question_start = output_str.find(\"Question:\") + len(\"Question:\")\n",
        "sql_start = output_str.find(\"SQL:\")\n",
        "\n",
        "question = output_str[question_start:sql_start].strip()\n",
        "\n",
        "sql = output_str[sql_start + len(\"SQL:\"):].strip()\n",
        "\n",
        "print(\"Extracted Question:\\n\", question)\n",
        "print(\"\\nExtracted SQL:\\n\", sql)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zKWMSvjbhvLj",
        "outputId": "07683938-a5e2-4800-f2fd-f0042a38f43e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Connected at: 2025-07-21 11:35:49.546852+00:00\n"
          ]
        }
      ],
      "source": [
        "import psycopg2\n",
        "\n",
        "conn = psycopg2.connect(\n",
        "    host=\"aws-0-ap-south-1.pooler.supabase.com\",\n",
        "    port=\"5432\",\n",
        "    database=\"postgres\",\n",
        "    user=\"postgres.xvoybvxbsdjeyehcrgoj\",\n",
        "    password=\"ammiabba401\"\n",
        ")\n",
        "\n",
        "cursor = conn.cursor()\n",
        "cursor.execute(\"SELECT NOW();\")\n",
        "print(\"✅ Connected at:\", cursor.fetchone()[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KNLtsZQByUR2",
        "outputId": "c70f2478-486c-4fb6-9ecb-abcd6b00a32b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results:\n",
            "('2025-06-16',)\n",
            "('2025-06-17',)\n",
            "('2025-06-18',)\n",
            "('2025-06-19',)\n",
            "('2025-06-20',)\n"
          ]
        }
      ],
      "source": [
        "cursor.execute(sql)\n",
        "rows = cursor.fetchall()\n",
        "\n",
        "print(\"Results:\")\n",
        "for row in rows:\n",
        "    print(row)\n",
        "\n",
        "cursor.close()\n",
        "conn.close()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = f\"\"\"\n",
        "You are a language model that converts SQL result rows into clear, natural language summaries.\n",
        "\n",
        "Given the user's original question and the structured SQL output, generate a concise and human-friendly answer that directly addresses the question.\n",
        "\n",
        "Important rules:\n",
        "- Do not repeat SQL structure or schema names.\n",
        "- Rephrase the results clearly and simply.\n",
        "- If dates or names are involved, format them naturally (e.g., \"June 12, 2025\").\n",
        "- Avoid unnecessary verbosity.\n",
        "\n",
        "User Question:\n",
        "{question}\n",
        "\n",
        "SQL Output:\n",
        "{rows}\n",
        "\n",
        "Generate a response:\n",
        "\"\"\"\n",
        "\n",
        "inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
        "outputs = model.generate(**inputs, max_new_tokens=256)\n",
        "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jV21Oidbe3xt",
        "outputId": "30be555b-1732-4262-9d9a-9cfebfc3b8bf"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:100001 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "You are a language model that converts SQL result rows into clear, natural language summaries.\n",
            "\n",
            "Given the user's original question and the structured SQL output, generate a concise and human-friendly answer that directly addresses the question.\n",
            "\n",
            "Important rules:\n",
            "- Do not repeat SQL structure or schema names.\n",
            "- Rephrase the results clearly and simply.\n",
            "- If dates or names are involved, format them naturally (e.g., \"June 12, 2025\").\n",
            "- Avoid unnecessary verbosity.\n",
            "\n",
            "User Question:\n",
            "on which dates adam ruiz was present in second week of june 2025\n",
            "\n",
            "SQL Output:\n",
            "[('2025-06-16',), ('2025-06-17',), ('2025-06-18',), ('2025-06-19',), ('2025-06-20',)]\n",
            "\n",
            "Generate a response:\n",
            "Adam Ruiz was present on the following dates in the second week of June 2025: June 16, 17, 18, 19, and 20.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c7052da3c8a64b23a3e324be64c9d4ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1dbe3ffd993d474996c58c9ae21f0910",
              "IPY_MODEL_d58727995b0143fe929cb8a700093144",
              "IPY_MODEL_eed41c4597df4625a585f27ca1d433e0"
            ],
            "layout": "IPY_MODEL_df11883ce94f4438bd4bb03c4432f258"
          }
        },
        "1dbe3ffd993d474996c58c9ae21f0910": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_945a714f3506408fa4acbde95435702a",
            "placeholder": "​",
            "style": "IPY_MODEL_81b9d68bff8042f890c7a43562a47b1d",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "d58727995b0143fe929cb8a700093144": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_754cff8ce3f54fc2979bee33b50b52ee",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c7171830fe7b42c4a75e2dad25fdbdad",
            "value": 3
          }
        },
        "eed41c4597df4625a585f27ca1d433e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2aefc576bad744aca9060ae165e3a7af",
            "placeholder": "​",
            "style": "IPY_MODEL_4f08fe1cea084c37a649b350e0c3c6ef",
            "value": " 3/3 [00:56&lt;00:00, 18.36s/it]"
          }
        },
        "df11883ce94f4438bd4bb03c4432f258": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "945a714f3506408fa4acbde95435702a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "81b9d68bff8042f890c7a43562a47b1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "754cff8ce3f54fc2979bee33b50b52ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7171830fe7b42c4a75e2dad25fdbdad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2aefc576bad744aca9060ae165e3a7af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f08fe1cea084c37a649b350e0c3c6ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}